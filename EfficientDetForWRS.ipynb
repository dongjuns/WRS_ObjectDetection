{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset\n",
    "There are 12 types of object class for World Robot Summit(WRS), we used 250 images.    \n",
    "Dataset is collected by Rasmus, https://github.com/RasmusHaugaard/wrs-data-collection    \n",
    "\n",
    "We split 200 for training and 50 for validation, each image pretty always contains 12 objects.    \n",
    "For EfficientDet, we go with COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Environment set up\n",
    "We use the EfficientDet tensorflow official version by Google.\n",
    "https://github.com/google/automl.git\n",
    "\n",
    "You also could read the tutorial notebook in the github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/google/automl.git\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train\n",
    "To train our custom model, we correctly need to prepare some files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(effdet) ~/djplace/automl/efficientdet$ pwd\n",
    "#/home/ubuntu/djplace/automl/efficientdet\n",
    "!tree -d\n",
    "'''\n",
    "├── wrs\n",
    "│   ├── annotations\n",
    "│   ├── train2017\n",
    "│   └── val2017\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotations/    \n",
    "instances_train2017.json  instances_val2017.json\n",
    "\n",
    "train2017/    \n",
    "200 images for training   \n",
    "\n",
    "val2017/    \n",
    "50 images for validation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'dataset/create_coco_tfrecord.py': [Errno 2] No such file or directory\n",
      "python: can't open file 'dataset/create_coco_tfrecord.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "!PYTHONPATH=\".:$PYTHONPATH\" python dataset/create_coco_tfrecord.py --image_dir=wrs/train2017/ --object_annotations_file=wrs/annotations/instances_train2017.json --output_file_prefix=wrs/train\n",
    "\n",
    "# validation\n",
    "!PYTHONPATH=\".:$PYTHONPATH\" python dataset/create_coco_tfrecord.py --image_dir=wrs/val2017/ --object_annotations_file=wrs/annotations/instances_val2017.json --output_file_prefix=wrs/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir wrs/tfrecords\n",
    "!mv wrs/*.records wrs/tfrecords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -d\n",
    "'''\n",
    "├── wrs\n",
    "│   ├── annotations\n",
    "│   ├── test\n",
    "│   ├── tfrecords\n",
    "│   ├── train2017\n",
    "│   └── val2017\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter yaml file for your custom model\n",
    "!vi wrs.yaml\n",
    "'''\n",
    "use_keras_model: False\n",
    "num_classes: 13\n",
    "label_map: {1: obj1, 2: obj2, 3: obj3, 4: obj4, 5: obj5, 6: obj6, 7: obj7, 8: obj8, 9: obj9, 10: obj10, 11: obj11, 12: obj12}\n",
    "moving_average_decay: 0\n",
    "var_freeze_expr: '(efficientnet|fpn_cells)'\n",
    "mixed_precision: True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained weight on the COCO dataset    \n",
    "# also can download another models from d0 ~ d7.    \n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco2/efficientdet-d4.tar.gz\n",
    "!tar xzf efficientdet-d4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --mode=train_and_eval --training_file_pattern=wrs/tfrecords/train*.tfrecord --validation_file_pattern=wrs/tfrecords/valid*.tfrecord --model_name=efficientdet-d4 --model_dir=efficientdet-d4-finetune --ckpt=efficientdet-d4 --train_batch_size=16 --num_examples_per_epoch=200 --num_epochs=100 --hparams=wrs.yaml\n",
    "\n",
    "# Using specific GPU, change the GPU device number\n",
    "# !CUDA_VISIBLE_DEVICES=1 python main.py --mode=train_and_eval --training_file_pattern=wrs/tfrecords/train*.tfrecord --validation_file_pattern=wrs/tfrecords/valid*.tfrecord --model_name=efficientdet-d1 --model_dir=efficientdet-d1-finetune --ckpt=efficientdet-d1 --train_batch_size=4 --num_examples_per_epoch=40 --num_epochs=1000 --hparams=wrs.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference\n",
    "Our images are RGB-A 4 channel images, therefore we need to transform it from 4 channel to RGB 3 channel.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wrs_RGBA2RGB.py\n",
    "\n",
    "# inference\n",
    "!python model_inspect.py --runmode=saved_model --model_name=efficientdet-d4 --saved_model_dir=tmp/saved_model/ --ckpt_path=efficientdet-d4-finetune/ --hparams=wrs.yaml --batch_size=1\n",
    "!python model_inspect.py --runmode=saved_model_infer --model_name=efficientdet-d4 --ckpt_path=wrs_efficientdet/efficientdet-d4-finetune/ --saved_model_dir=tmp/saved_model/efficientdet-d4_frozen.pb --input_image=./wrs/test/*.png --output_image_dir=tmp/img_output --hparams=wrs.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
